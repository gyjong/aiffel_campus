{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.gradio.app/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-4.26.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting altair<6.0,>=4.2.0 (from gradio)\n",
      "  Downloading altair-5.3.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting fastapi (from gradio)\n",
      "  Downloading fastapi-0.110.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gradio-client==0.15.1 (from gradio)\n",
      "  Downloading gradio_client-0.15.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx>=0.24.1 (from gradio)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting huggingface-hub>=0.19.3 (from gradio)\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/anaconda3/envs/aiffel_py39/lib/python3.9/site-packages (from gradio) (6.4.0)\n",
      "Collecting jinja2<4.0 (from gradio)\n",
      "  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /opt/anaconda3/envs/aiffel_py39/lib/python3.9/site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /opt/anaconda3/envs/aiffel_py39/lib/python3.9/site-packages (from gradio) (3.8.4)\n",
      "Requirement already satisfied: numpy~=1.0 in /opt/anaconda3/envs/aiffel_py39/lib/python3.9/site-packages (from gradio) (1.26.4)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.10.0-cp39-cp39-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/anaconda3/envs/aiffel_py39/lib/python3.9/site-packages (from gradio) (24.0)\n",
      "Collecting pandas<3.0,>=1.0 (from gradio)\n",
      "  Downloading pandas-2.2.2.tar.gz (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pillow<11.0,>=8.0 in /opt/anaconda3/envs/aiffel_py39/lib/python3.9/site-packages (from gradio) (10.3.0)\n",
      "Collecting pydantic>=2.0 (from gradio)\n",
      "  Using cached pydantic-2.6.4-py3-none-any.whl.metadata (85 kB)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from gradio)\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pyyaml<7.0,>=5.0 (from gradio)\n",
      "  Downloading PyYAML-6.0.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting ruff>=0.2.2 (from gradio)\n",
      "  Downloading ruff-0.3.5-py3-none-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (23 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.9 (from typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio)\n",
      "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /opt/anaconda3/envs/aiffel_py39/lib/python3.9/site-packages (from gradio) (4.11.0)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.29.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting fsspec (from gradio-client==0.15.1->gradio)\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting websockets<12.0,>=10.0 (from gradio-client==0.15.1->gradio)\n",
      "  Downloading websockets-11.0.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting jsonschema>=3.0 (from altair<6.0,>=4.2.0->gradio)\n",
      "  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting toolz (from altair<6.0,>=4.2.0->gradio)\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting anyio (from httpx>=0.24.1->gradio)\n",
      "  Using cached anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/aiffel_py39/lib/python3.9/site-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/aiffel_py39/lib/python3.9/site-packages (from httpx>=0.24.1->gradio) (3.6)\n",
      "Collecting sniffio (from httpx>=0.24.1->gradio)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.19.3->gradio)\n",
      "  Downloading filelock-3.13.4-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/aiffel_py39/lib/python3.9/site-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub>=0.19.3->gradio)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/anaconda3/envs/aiffel_py39/lib/python3.9/site-packages (from importlib-resources<7.0,>=1.3->gradio) (3.17.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/aiffel_py39/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/aiffel_py39/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/aiffel_py39/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/aiffel_py39/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/aiffel_py39/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/aiffel_py39/lib/python3.9/site-packages (from matplotlib~=3.0->gradio) (2.9.0)\n",
      "Collecting pytz>=2020.1 (from pandas<3.0,>=1.0->gradio)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3.0,>=1.0->gradio)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=2.0->gradio)\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.16.3 (from pydantic>=2.0->gradio)\n",
      "  Using cached pydantic_core-2.16.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.5 kB)\n",
      "Collecting click>=8.0.0 (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/envs/aiffel_py39/lib/python3.9/site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio) (13.7.1)\n",
      "\u001b[33mWARNING: typer 0.12.3 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
      "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio)\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio)\n",
      "  Downloading jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio)\n",
      "  Downloading referencing-0.34.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio)\n",
      "  Downloading rpds_py-0.18.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/aiffel_py39/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/aiffel_py39/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/aiffel_py39/lib/python3.9/site-packages (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio) (2.17.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/anaconda3/envs/aiffel_py39/lib/python3.9/site-packages (from anyio->httpx>=0.24.1->gradio) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/aiffel_py39/lib/python3.9/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/aiffel_py39/lib/python3.9/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.2.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/aiffel_py39/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio) (0.1.2)\n",
      "Downloading gradio-4.26.0-py3-none-any.whl (17.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-0.15.1-py3-none-any.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading altair-5.3.0-py3-none-any.whl (857 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.8/857.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.0-cp39-cp39-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (251 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.7/251.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pydantic-2.6.4-py3-none-any.whl (394 kB)\n",
      "Using cached pydantic_core-2.16.3-cp39-cp39-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading PyYAML-6.0.1-cp39-cp39-macosx_11_0_arm64.whl (174 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.4/174.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ruff-0.3.5-py3-none-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (16.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.110.1-py3-none-any.whl (91 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Downloading websockets-11.0.3-cp39-cp39-macosx_11_0_arm64.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.13.4-py3-none-any.whl (11 kB)\n",
      "Downloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Downloading referencing-0.34.0-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.18.0-cp39-cp39-macosx_11_0_arm64.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.0/331.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pandas, ffmpy\n",
      "  Building wheel for pandas (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pandas: filename=pandas-2.2.2-cp39-cp39-macosx_14_0_arm64.whl size=40195437 sha256=e8d546a0816daec6feb104e715ae6f5b3e5f66a3bce3ef0024965c146c996dd7\n",
      "  Stored in directory: /Users/kenny_jung/Library/Caches/pip/wheels/d0/e8/5e/1d99de57ccf6817dbf2a84b98291b96ffd348435344817b609\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5582 sha256=8d951e769ecf373404d579df0312da5c4c1cde4315b396723a4331bc72d465b5\n",
      "  Stored in directory: /Users/kenny_jung/Library/Caches/pip/wheels/fd/f6/eb/b42ef38e0c6298906279494f5fcf10aee4b4bd07346b8f900b\n",
      "Successfully built pandas ffmpy\n",
      "Installing collected packages: pytz, pydub, ffmpy, websockets, tzdata, tqdm, toolz, tomlkit, sniffio, shellingham, semantic-version, ruff, rpds-py, pyyaml, python-multipart, pydantic-core, orjson, jinja2, h11, fsspec, filelock, click, attrs, annotated-types, aiofiles, uvicorn, referencing, pydantic, pandas, huggingface-hub, httpcore, anyio, typer, starlette, jsonschema-specifications, httpx, jsonschema, gradio-client, fastapi, altair, gradio\n",
      "Successfully installed aiofiles-23.2.1 altair-5.3.0 annotated-types-0.6.0 anyio-4.3.0 attrs-23.2.0 click-8.1.7 fastapi-0.110.1 ffmpy-0.3.2 filelock-3.13.4 fsspec-2024.3.1 gradio-4.26.0 gradio-client-0.15.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 huggingface-hub-0.22.2 jinja2-3.1.3 jsonschema-4.21.1 jsonschema-specifications-2023.12.1 orjson-3.10.0 pandas-2.2.2 pydantic-2.6.4 pydantic-core-2.16.3 pydub-0.25.1 python-multipart-0.0.9 pytz-2024.1 pyyaml-6.0.1 referencing-0.34.0 rpds-py-0.18.0 ruff-0.3.5 semantic-version-2.10.0 shellingham-1.5.4 sniffio-1.3.1 starlette-0.37.2 tomlkit-0.12.0 toolz-0.12.1 tqdm-4.66.2 typer-0.12.3 tzdata-2024.1 uvicorn-0.29.0 websockets-11.0.3\n"
     ]
    }
   ],
   "source": [
    "# !pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aiffel_py39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(name):\n",
    "    return \"Hello \" + name + \"!\"\n",
    "\n",
    "demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
    "demo.launch()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Running on public URL: https://2c8ff4d86054fc2881.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://2c8ff4d86054fc2881.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7861 <> https://2c8ff4d86054fc2881.gradio.live\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그라디오 라이브러리를 불러옵니다.\n",
    "import gradio as gr\n",
    "\n",
    "# 인사말 함수를 정의합니다.\n",
    "# 이 함수는 이름을 매개변수로 받아 \"안녕! \" 이라는 문자열을 붙여 반환합니다.\n",
    "def greet(name):\n",
    "    return \"안녕! \" + name\n",
    "\n",
    "# 인터페이스 'demo'를 실행할 때 호출할 함수를 지정합니다.\n",
    "# 이 함수의 인자로 inputs의 내용이 입력되고,\n",
    "# 함수의 출력이 outputs에 표시됩니다.\n",
    "demo = gr.Interface(\n",
    "    fn=greet,\n",
    "    inputs=\"text\",  # 텍스트 입력 창을 설정합니다.\n",
    "    outputs=\"text\"  # 텍스트 출력 창을 설정합니다.\n",
    ")\n",
    "\n",
    "# 그라디오 인터페이스를 실행합니다.\n",
    "# 실행하면 사용자는 텍스트 입력창에 이름을 입력할 수 있고,\n",
    "# 그 결과 \"안녕! \" + 입력한 이름 이라는 출력을 볼 수 있습니다.\n",
    "demo.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Running on public URL: https://bed1297c49e8737efc.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://bed1297c49e8737efc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7861 <> https://bed1297c49e8737efc.gradio.live\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그라디오 라이브러리를 불러옵니다.\n",
    "import gradio as gr\n",
    "\n",
    "# 인사말 함수를 정의합니다.\n",
    "# 이 함수는 이름을 매개변수로 받아 \"안녕! \" 이라는 문자열을 붙여 반환합니다.\n",
    "def greet(name):\n",
    "    return \"안녕! \" + name\n",
    "\n",
    "# 인터페이스 'demo'를 실행할 때 호출할 함수를 지정합니다.\n",
    "# 이 함수의 인자로 inputs의 내용이 입력되고, 함수의 출력이 outputs에 표시됩니다.\n",
    "demo = gr.Interface(\n",
    "    fn = greet,\n",
    "\n",
    "    # 사용자가 입력을 제공할 텍스트박스를 정의하고,\n",
    "    # 플레이스홀더(placeholder)를 사용하여 입력창에 힌트를 제공합니다.\n",
    "    inputs = gr.Textbox(lines=2, placeholder=\"이름을 작성하세요.\"),\n",
    "\n",
    "    outputs=\"text\"  # 텍스트 출력 창을 설정합니다.\n",
    ")\n",
    "\n",
    "# 그라디오 인터페이스를 실행합니다.\n",
    "# 실행하면 사용자는 텍스트 입력창에 이름을 입력할 수 있고,\n",
    "# 그 결과 \"안녕! \" + 입력한 이름 이라는 출력을 볼 수 있습니다.\n",
    "demo.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Running on public URL: https://2a1232e0f40f8ba0c3.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://2a1232e0f40f8ba0c3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7861 <> https://2a1232e0f40f8ba0c3.gradio.live\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그라디오 라이브러리를 불러옵니다.\n",
    "import gradio as gr\n",
    "\n",
    "# 인사말 함수를 정의합니다.\n",
    "# 이 함수는 이름을 매개변수로 받아 \"안녕! \" 이라는 문자열을 붙여 반환합니다.\n",
    "def greet(name):\n",
    "    return \"안녕! \" + name\n",
    "\n",
    "# gr.Blocks()를 사용하여 인터페이스를 생성합니다.\n",
    "with gr.Blocks() as demo:\n",
    "\n",
    "    # '이름'이라는 레이블을 가진 입력 텍스트박스를 생성합니다.\n",
    "    name = gr.Textbox(label=\"이름\")\n",
    "\n",
    "    # '출력창'이라는 레이블을 가진 출력 텍스트박스를 생성합니다.\n",
    "    output = gr.Textbox(label=\"출력창\")\n",
    "\n",
    "    # '인사'라는 레이블을 가진 버튼을 생성합니다.\n",
    "    greet_btn = gr.Button(\"인사\")\n",
    "\n",
    "    # 버튼 클릭 시 greet 함수가 실행되도록 합니다.\n",
    "    greet_btn.click(fn=greet, inputs=name, outputs=output, api_name=\"greet\")\n",
    "\n",
    "# 인터페이스를 실행합니다.\n",
    "# 이제 사용자가 이름을 입력하고 '인사' 버튼을 클릭하면\n",
    "# \"안녕! \" + 입력한 이름 이라는 메시지가 출력창에 표시됩니다.\n",
    "demo.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Running on public URL: https://7f74071996faa1d6eb.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://7f74071996faa1d6eb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7861 <> https://7f74071996faa1d6eb.gradio.live\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr  # 그라디오 라이브러리를 불러옵니다.\n",
    "import random  # 무작위 선택을 위한 라이브러리를 불러옵니다.\n",
    "import time  # 시간 지연을 위한 라이브러리를 불러옵니다.\n",
    "\n",
    "# 채팅봇의 응답을 처리하는 함수를 정의합니다.\n",
    "def respond(message, chat_history):\n",
    "\n",
    "    # 미리 정의된 응답 중 하나를 무작위로 선택합니다.\n",
    "    bot_message = random.choice([\"어떻게 지내세요?\", \"좋아해요\", \"배고파요\"])\n",
    "\n",
    "    # 채팅 기록에 사용자의 메시지와 봇의 응답을 추가합니다.\n",
    "    chat_history.append((message, bot_message))\n",
    "\n",
    "    # 응답을 할 때 시간 지연을 만들어줍니다.\n",
    "    # 이는 채팅봇이 실시간으로 답변하고 있는 것처럼 보이게 합니다.\n",
    "    time.sleep(1)\n",
    "\n",
    "    return \"\", chat_history  # 수정된 채팅 기록을 반환합니다.\n",
    "\n",
    "# gr.Blocks()를 사용하여 인터페이스를 생성합니다.\n",
    "with gr.Blocks() as demo:\n",
    "\n",
    "    # '채팅창'이라는 레이블을 가진 채팅봇 컴포넌트를 생성합니다.\n",
    "    chatbot = gr.Chatbot(label=\"채팅창\")\n",
    "\n",
    "    # '입력'이라는 레이블을 가진 텍스트박스를 생성합니다.\n",
    "    msg = gr.Textbox(label=\"입력\")\n",
    "\n",
    "    # '초기화'라는 레이블을 가진 버튼을 생성합니다.\n",
    "    clear = gr.Button(\"초기화\")\n",
    "\n",
    "    # 텍스트박스에 메시지를 입력하고 제출하면 respond 함수가 호출되도록 합니다.\n",
    "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "\n",
    "    # '초기화' 버튼을 클릭하면 채팅 기록을 초기화합니다.\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "# 인터페이스를 실행합니다.\n",
    "# 실행하면 사용자는 '입력' 텍스트박스에 메시지를 작성하고 제출할 수 있으며,\n",
    "# '초기화' 버튼을 통해 채팅 기록을 초기화할 수 있습니다.\n",
    "demo.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "\n",
    "load_dotenv('api.env') \n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "max_tokens = 200\n",
    "temperature = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.17.0'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================\n",
      "Feedback from ChatGPT\n",
      "안녕하세요! 저는 인공지능 챗봇입니다. 무엇을 도와드릴까요?\n",
      "-----------------------------------------------------------------------------------\n",
      "CompletionUsage(completion_tokens=36, prompt_tokens=18, total_tokens=54)\n",
      "===================================================================================\n"
     ]
    }
   ],
   "source": [
    "# response = openai.Completion.create(\n",
    "\n",
    "#     # 사용할 AI 모델을 지정합니다.\n",
    "#     # \"text-davinci-003\" 모델이 2024년 1월에 deprecate되어,\n",
    "#     # \"gpt-3.5-turbo-instruct\" 모델을 대신 사용하였습니다.\n",
    "#     model=\"gpt-3.5-turbo-instruct\",\n",
    "\n",
    "#     # AI 모델에게 전달할 프롬프트를 지정합니다.\n",
    "#     prompt=\"안녕? 넌 누구니?\",\n",
    "\n",
    "#     # 생성될 텍스트의 최대 토큰 수를 지정합니다.\n",
    "#     # 여기서는 256개의 토큰을 지정하였습니다.\n",
    "#     max_tokens=max_tokens,\n",
    "\n",
    "#     # 출력의 다양성을 조절합니다.\n",
    "#     # 값이 0이면 가장 확률이 높은 텍스트를 생성하고,\n",
    "#     # 값이 1에 가까울수록 더 다양한 텍스트를 생성합니다.\n",
    "#     temperature=temperature\n",
    "# )\n",
    "\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": '녕? 넌 누구니?',\n",
    "            },\n",
    "        ],\n",
    "        max_tokens = max_tokens,\n",
    "        temperature = temperature\n",
    "    )\n",
    "\n",
    "print('===================================================================================')\n",
    "print('Feedback from ChatGPT')\n",
    "print(completion.choices[0].message.content)\n",
    "print('-----------------------------------------------------------------------------------')\n",
    "print(completion.usage)\n",
    "print('===================================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-9CjlbKa8yBKy0fJSOKAKB89koqD6F', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='안녕하세요! 저는 인공지능 챗봇입니다. 무엇을 도와드릴까요?', role='assistant', function_call=None, tool_calls=None))], created=1712822891, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_c2295e73ad', usage=CompletionUsage(completion_tokens=36, prompt_tokens=18, total_tokens=54))\n"
     ]
    }
   ],
   "source": [
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "\n",
    "load_dotenv('api.env') \n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "max_tokens = 200\n",
    "temperature = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Running on public URL: https://1a77faedffd162bec1.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://1a77faedffd162bec1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7861 <> https://1a77faedffd162bec1.gradio.live\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 채팅봇의 응답을 처리하는 함수를 정의합니다.\n",
    "def respond(message, chat_history):\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": message,\n",
    "            },\n",
    "        ],\n",
    "        max_tokens = max_tokens,\n",
    "        temperature = temperature\n",
    "    )\n",
    "\n",
    "\n",
    "    # response = openai.Completion.create(\n",
    "\n",
    "    #     # 사용할 AI 모델을 지정합니다.\n",
    "    #     # 여기서는 \"gpt-3.5-turbo-instruct\" 모델을 사용하였습니다.\n",
    "    #     model=\"gpt-3.5-turbo-instruct\",\n",
    "\n",
    "    #     # AI 모델에게 전달할 프롬프트를 지정합니다.\n",
    "    #     prompt=message,\n",
    "\n",
    "    #     # 생성될 텍스트의 최대 토큰 수를 지정합니다.\n",
    "    #     # 여기서는 256개의 토큰을 지정하였습니다.\n",
    "    #     max_tokens=256,\n",
    "\n",
    "    #     # 출력의 다양성을 조절합니다.\n",
    "    #     # 값이 0이면 가장 확률이 높은 텍스트를 생성하고,\n",
    "    #     # 값이 1에 가까울수록 더 다양한 텍스트를 생성합니다.\n",
    "    #     temperature=0\n",
    "    # )\n",
    "\n",
    "    # print(response)\n",
    "\n",
    "    # 응답 메시지(JSON)에서 출력 텍스트만 추출합니다.\n",
    "    bot_message = response.choices[0].message.content\n",
    "\n",
    "    # 채팅 기록에 사용자의 메시지와 봇의 응답을 추가합니다.\n",
    "    chat_history.append((message, bot_message))\n",
    "\n",
    "    return \"\", chat_history  # 수정된 채팅 기록을 반환합니다.\n",
    "\n",
    "\n",
    "# gr.Blocks()를 사용하여 인터페이스를 생성합니다.\n",
    "with gr.Blocks() as demo:\n",
    "\n",
    "    # '채팅창'이라는 레이블을 가진 채팅봇 컴포넌트를 생성합니다.\n",
    "    chatbot = gr.Chatbot(label=\"채팅창\")\n",
    "\n",
    "    # '입력'이라는 레이블을 가진 텍스트박스를 생성합니다.\n",
    "    msg = gr.Textbox(label=\"입력\")\n",
    "\n",
    "    # '초기화'라는 레이블을 가진 버튼을 생성합니다.\n",
    "    clear = gr.Button(\"초기화\")\n",
    "\n",
    "    # 텍스트박스에 메시지를 입력하고 제출하면 respond 함수가 호출되도록 합니다.\n",
    "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "\n",
    "    # '초기화' 버튼을 클릭하면 채팅 기록을 초기화합니다.\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "# 인터페이스를 실행합니다.\n",
    "# 실행하면 사용자는 '입력' 텍스트박스에 메시지를 작성하고 제출할 수 있으며,\n",
    "# '초기화' 버튼을 통해 채팅 기록을 초기화할 수 있습니다.\n",
    "demo.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 나만의 카페점원 서비스 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "import gradio as gr\n",
    "\n",
    "load_dotenv('api.env') \n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "max_tokens = 200\n",
    "temperature = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "커리는 다양한 건강상의 이점을 제공하는 향신료로 알려져 있습니다. 이를테면:\n",
      "\n",
      "1. 항염증 효과: 커리는 강력한 항염증 효과를 가지고 있어 관절염, 염증성 장 질환, 심혈관 질환 등 염증과 관련된 질병을 예방하고 치료하는 데 도움을 줄 수 있습니다.\n",
      "\n",
      "2. 항산화 성분: 커리에는 항산화 성분이 풍부하게 함유되어 있어 세포 손상을 예방하고 세포 건\n",
      "CompletionUsage(completion_tokens=199, prompt_tokens=36, total_tokens=235)\n"
     ]
    }
   ],
   "source": [
    "# 채팅 완성 API를 호출합니다.\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"커리는 몸에 좋은가? 항목별로 정리해서 알려줘.\",\n",
    "        },\n",
    "    ],\n",
    "    max_tokens = max_tokens,\n",
    "    temperature = temperature\n",
    ")\n",
    "\n",
    "print()\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "print(response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "Running on public URL: https://8810d7f8ec26db3b9f.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://8810d7f8ec26db3b9f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7863 <> https://8810d7f8ec26db3b9f.gradio.live\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 채팅봇의 응답을 처리하는 함수를 정의합니다.\n",
    "def respond(user_input_message, chatbot_ui, state_message_history):\n",
    "\n",
    "    # 채팅 메시지 히스토리에 사용자 메시지를 추가합니다.\n",
    "    state_message_history.append({\n",
    "        'role': 'user', \n",
    "        'content': user_input_message})\n",
    "    \n",
    "    # 채팅 완성 API를 호출합니다.\n",
    "    # response = openai.chat.completions.create(\n",
    "    #     model=\"gpt-3.5-turbo\",\n",
    "    #     messages=[\n",
    "    #         {\n",
    "    #             \"role\": \"user\",\n",
    "    #             \"content\": state_message_history,\n",
    "    #         },\n",
    "    #     ],\n",
    "    #     max_tokens = max_tokens,\n",
    "    #     temperature = temperature\n",
    "    # )\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=state_message_history,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "\n",
    "    # 응답 JSON에서 출력 텍스트를 추출합니다. \n",
    "    ai_respond_message = response.choices[0].message.content\n",
    " \n",
    "    # 채팅 메시지 히스토리에 어시트턴트 메시지를 추가합니다.\n",
    "    state_message_history.append({'role': 'assistant', 'content': ai_respond_message})\n",
    "    \n",
    "    # 채팅 기록에 사용자의 메시지와 봇의 응답을 추가합니다.\n",
    "    chatbot_ui.append((user_input_message, ai_respond_message))\n",
    "\n",
    "    # 수정된 채팅 기록을 반환합니다.\n",
    "    return \"\", chatbot_ui, state_message_history\n",
    "\n",
    "\n",
    "# gr.Blocks()를 사용하여 인터페이스를 생성합니다.\n",
    "with gr.Blocks() as demo:\n",
    "    \n",
    "    state_message_history = gr.State([{\n",
    "        'role': 'system',\n",
    "        'content': \"\"\"너는 친절하고 정확한 카페 점원이야. 사용자가 음료를 주문하면 접수와 계산을 한다. 만약 사용자가 매장에 없는 메뉴를 요청하면, 죄송하다고 얘기하고, 다시 [메뉴]를 안내한다. 매장 메뉴는 아래 [메뉴]와 같다. 주문을 마쳤다면, 총금액을 알려주고 결제방식에 대해서 물어본다. 결제를 마치면 음료를 제조하고, 고객에게 기다려달라고 한다.\n",
    "[메뉴]\n",
    "아메리카노, 5000원\n",
    "라떼, 6000원\n",
    "아이스 아메리카노, 5500원\"\"\"\n",
    "    }])\n",
    "        \n",
    "    # '채팅창'이라는 레이블을 가진 채팅봇 컴포넌트를 생성합니다.\n",
    "    chatbot_ui = gr.Chatbot(label=\"채팅창\")\n",
    "\n",
    "    # '입력'이라는 레이블을 가진 텍스트박스를 생성합니다.\n",
    "    user_input_message = gr.Textbox(label=\"입력\")\n",
    "    \n",
    "    # 텍스트박스에 메시지를 입력하고 제출하면 respond 함수가 호출되도록 합니다.\n",
    "    user_input_message.submit(respond, \n",
    "        [user_input_message, chatbot_ui, state_message_history],\n",
    "        [user_input_message, chatbot_ui, state_message_history])  \n",
    "\n",
    "# 인터페이스를 실행합니다.\n",
    "# 사용자는 '입력' 텍스트박스에 메시지를 작성하고 제출할 수 있습니다.\n",
    "demo.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사용자 맞춤현 서비스 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "import gradio as gr\n",
    "\n",
    "load_dotenv('api.env') \n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "max_tokens = 200\n",
    "temperature = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "# 데이터베이스 파일을 생성합니다.\n",
    "def init_db():\n",
    "    # user_message.db 파일에 연결합니다. (파일이 없다면 생성합니다.)\n",
    "    conn = sqlite3.connect('./user_message.db')\n",
    "    curs = conn.cursor()\n",
    "    # (sql 문법) id, user_id, create_datetime, message 항목을 가지는\n",
    "    # 테이블 message_record 생성\n",
    "    curs.execute('CREATE TABLE IF NOT EXISTS message_record(id INTEGER PRIMARY KEY AUTOINCREMENT, user_id TEXT, create_datetime TEXT, message TEXT)')\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "# 새로운 메시지 데이터를 저장합니다.\n",
    "def add_message(user_id, message):\n",
    "    conn = sqlite3.connect('./user_message.db')\n",
    "    curs = conn.cursor()\n",
    "    # (sql 문법) message_record 테이블에 유저id, 현재 시각, 메시지 내용을 추가\n",
    "    curs.execute(\"INSERT INTO message_record VALUES (null, ?, ?, ?)\", (user_id, str(datetime.now()), message))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "# 저장된 메시지 데이터를 가져옵니다.\n",
    "def get_message_history(user_id):\n",
    "    conn = sqlite3.connect('./user_message.db')\n",
    "    curs = conn.cursor()\n",
    "    # (sql 문법) message_record 테이블에서 특정 유저id 값을 가지는 데이터 가져오기\n",
    "    query = curs.execute(\"SELECT * from message_record where user_id = ?\", (user_id,))\n",
    "    ret = query.fetchall()\n",
    "    conn.close()\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API를 사용하여 이전 대화 내용을 요약합니다.\n",
    "def summary(history):\n",
    "    \n",
    "    prompt = [{'role':'system', 'content': '아래는 이전 대화 기록이다. 주문했던 음료, 개수, 주문 시간 정보 등을 요약해'},\n",
    "                {'role':'user', 'content': history}]\n",
    "                \n",
    "    # 채팅 완성 API를 호출합니다.\n",
    "    # respond = openai.ChatCompletion.create(\n",
    "    #     model = 'gpt-3.5-turbo',\n",
    "    #     messages = prompt,\n",
    "    #     temperature = 1.0\n",
    "    # )        \n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=prompt,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "\n",
    "    # return respond['choices'][0]['message']['content']\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 채팅봇의 응답을 처리하는 함수를 정의합니다.\n",
    "def respond(user_input_message, chatbot_ui, state_message_history):\n",
    "\n",
    "    ##### 따옴표 안쪽에 여러분의 이름을 넣어보세요! #####\n",
    "    user_name = 'kenny'\n",
    "    #####\n",
    "    \n",
    "    history_summary_text = ''\n",
    "    \n",
    "    # 고객 방문 시 해당 고객의 이전 방문 기록이 있는지 확인\n",
    "    if len(state_message_history) == 0:\n",
    "        \n",
    "        history = get_message_history(user_name)\n",
    "        \n",
    "        # 이전 방문 기록이 없는 경우\n",
    "        if len(history) == 0:\n",
    "            history_summary_text = \"방문 기록이 없습니다.\"\n",
    "        \n",
    "        # 이전 방문 기록이 존재하는 경우\n",
    "        if len(history) > 0:\n",
    "            history = [', '.join(map(str, t)) for t in history]\n",
    "            history = '|'.join(history)\n",
    "            history_summary_text = summary(history)\n",
    "\n",
    "    state_message_history.append({\n",
    "        'role': 'system',\n",
    "        'content': \"\"\"너는 친절하고 정확한 카페 점원이야. [기록]은 이전에 사용자가 방문했을 때 주문했던 기록이다. [기록]을 바탕으로 사용자를 기억하고 단골인 것처럼 친절하게 인사해. 사용자가 음료를 주문하면 접수와 계산을 한다. 만약 사용자가 매장에 없는 메뉴를 요청하면, 죄송하다고 얘기하고, 다시 [메뉴]를 안내한다. 매장 메뉴는 아래 [메뉴]와 같다. 주문을 마쳤다면, 총금액을 알려주고 결제방식에 대해서 물어본다. 결제를 마치면 음료를 제조하고, 고객에게 기다려달라고 한다.\n",
    "[기록]\n",
    "\"\"\" + history_summary_text +\n",
    "\"\"\"\n",
    "[메뉴]\n",
    "아메리카노, 5000원\n",
    "라떼, 6000원\n",
    "아이스 아메리카노, 5500원\"\"\"\n",
    "    })\n",
    "    \n",
    "    # 채팅 메시지 히스토리에 사용자 메시지를 추가합니다.\n",
    "    state_message_history.append({'role': 'user', 'content': user_input_message})\n",
    "    add_message(user_name, user_input_message)\n",
    "    \n",
    "    # 채팅 완성 API를 호출합니다.\n",
    "    # respond = openai.ChatCompletion.create(\n",
    "    #     model = 'gpt-3.5-turbo',\n",
    "    #     messages = state_message_history,\n",
    "    #     temperature = 0.0\n",
    "    # )\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=state_message_history,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature\n",
    "    )    \n",
    " \n",
    "    # 응답 JSON에서 출력 텍스트를 추출합니다.\n",
    "    # ai_respond_message = respond['choices'][0]['message']['content']\n",
    "    ai_respond_message = response.choices[0].message.content\n",
    "\n",
    "    # 채팅 메시지 히스토리에 어시트턴트 메시지를 추가합니다.\n",
    "    state_message_history.append({'role': 'assistant', 'content': ai_respond_message})\n",
    "    add_message(user_name, ai_respond_message)\n",
    "    \n",
    "    # 채팅 기록에 사용자의 메시지와 봇의 응답을 추가합니다.\n",
    "    chatbot_ui.append((user_input_message, ai_respond_message))\n",
    "\n",
    "    # 수정된 채팅 기록을 반환합니다.\n",
    "    return \"\", chatbot_ui, state_message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "Running on public URL: https://f0e875ab260d82c7d6.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://f0e875ab260d82c7d6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터베이스 테이블을 생성합니다.\n",
    "init_db()\n",
    "\n",
    "# gr.Blocks()를 사용하여 인터페이스를 생성합니다.\n",
    "with gr.Blocks() as demo:\n",
    "    \n",
    "    state_message_history = gr.State([])\n",
    "\n",
    "    # '채팅창'이라는 레이블을 가진 채팅봇 컴포넌트를 생성합니다.\n",
    "    chatbot_ui = gr.Chatbot(label=\"채팅창\")\n",
    "\n",
    "    # '입력'이라는 레이블을 가진 텍스트박스를 생성합니다.\n",
    "    user_input_message = gr.Textbox(label=\"입력\")\n",
    "    \n",
    "    # 텍스트박스에 메시지를 입력하고 제출하면 respond 함수가 호출되도록 합니다.\n",
    "    user_input_message.submit(respond, [user_input_message, chatbot_ui, state_message_history], \n",
    "                                       [user_input_message, chatbot_ui, state_message_history])  \n",
    "\n",
    "# 인터페이스를 실행합니다.\n",
    "# 사용자는 '입력' 텍스트박스에 메시지를 작성하고 제출할 수 있습니다.\n",
    "demo.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
